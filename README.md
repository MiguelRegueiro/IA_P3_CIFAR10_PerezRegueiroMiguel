# IA_P3_CIFAR10_PerezRegueiroMiguel

# CIFAR-10 CNN â€“ PrÃ¡ctica 3  
> Autor: TuNombre Apellido â€“ Curso 2025/26

[![Python 3.10](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.x](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://tensorflow.org)
[![Release](https://img.shields.io/github/v/release/tu-usuario/IA_P3_CIFAR10_Apellido?include_prereleases)](https://github.com/tu-usuario/IA_P3_CIFAR10_Apellido/releases/tag/v1.0-P3-CIFAR10_Apellido)

Repositorio reproducible de la prÃ¡ctica **â€œVisiÃ³n profunda con CNN en CIFAR-10â€**.  
Incluye: notebooks, curvas, matrices de confusiÃ³n y estudio de ablaciÃ³n.

## ğŸ“¦ Estructura
```
IA_P3_CIFAR10_Apellido/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ CIFAR10_CNN_Apellido.ipynb   # notebook principal (colab)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ data_meta.json               # hash y formas de datos
â”‚   â”œâ”€â”€ params.yaml                  # hiper-parÃ¡metros
â”‚   â”œâ”€â”€ history_*.csv                # curvas de entrenamiento
â”‚   â””â”€â”€ metrics_*.json               # accuracies finales
â”œâ”€â”€ figuras/
â”‚   â”œâ”€â”€ muestras_cifar10.png
â”‚   â”œâ”€â”€ confusion_matrix_cnn3.png
â”‚   â”œâ”€â”€ errores_cnn3.png
â”‚   â””â”€â”€ curvas_resumen.png
â”œâ”€â”€ env/
â”‚   â”œâ”€â”€ ENVIRONMENT.md               # versiones
â”‚   â””â”€â”€ requirements.txt             # pip freeze
â””â”€â”€ README.md                        # este archivo
```

# A) Conceptos clave â€“ VisiÃ³n profunda con CNN en CIFAR-10

## Mapa rÃ¡pido del tema
CIFAR-10 son 60 000 imÃ¡genes pequeÃ±as (32Ã—32 pÃ­xeles y 3 canales de color) divididas en 10 clases: aviÃ³n, coche, pÃ¡jaro, gato, venado, perro, rana, caballo, barco y camiÃ³n.  
Una CNN supera a una red densa porque **no aplana** la imagen: mantiene la estructura 2D y usa **convoluciones** para detectar bordes, texturas y formas. El **pooling** aÃ±ade **invarianza a pequeÃ±as traslaciones**: si un gato se mueve unos pÃ­xeles, el filtro sigue activÃ¡ndose. Aplanar los 3 072 pÃ­xeles al principio obligarÃ­a a la red a aprender de memoria la posiciÃ³n exacta de cada pÃ­xel, con **800 000 parÃ¡metros** solo en la primera capa, y **sensible al ruido de fondo**.

## ConvoluciÃ³n sin magia
Un filtro (kernel) es una matriz pequeÃ±a (ej. 3Ã—3) que se desliza sobre la imagen.  
Hiper-parÃ¡metros: **tamaÃ±o**, **stride** (paso), **padding** (borde) y **canales** (profundidad).  
Ejemplo rÃ¡pido: imagen 5Ã—5Ã—1, kernel 3Ã—3, stride=1, padding=0 â†’ salida 3Ã—3Ã—1.  
Coste: 9Ã—3Ã—3 = 81 multiplicaciones por canal; si usamos 32 filtros â†’ 2 592 ops.

## Pooling y por quÃ© importa
**MaxPooling** conserva el valor mÃ¡ximo dentro de una ventana (2Ã—2): preserva bordes fuertes y reduce ruido.  
**AveragePooling** suaviza, Ãºtil en fondos homogÃ©neos.  
Ambos **dividen a la mitad** la resoluciÃ³n, aumentan la **invarianza traslacional** y **disminuyen sobreajuste** al reducir parÃ¡metros.  
Micro-ejemplo: ventana 2Ã—2 con valores [[4,2],[3,6]] â†’ Max=6, Average=3.75.

## Arquitectura tÃ­pica de una CNN simple
Input(32Ã—32Ã—3)  
â†’ Conv2D(32 filtros, 3Ã—3) + ReLU (detecta bordes)  
â†’ MaxPool2D(2Ã—2) (reduce a 16Ã—16)  
â†’ Conv2D(64 filtros, 3Ã—3) + ReLU (formas complejas)  
â†’ MaxPool2D(2Ã—2) (8Ã—8)  
â†’ Flatten (aplanado solo al final)  
â†’ Dense(128) + ReLU (combinaciÃ³n global)  
â†’ Dropout(0.5) (regularizaciÃ³n)  
â†’ Dense(10, softmax) (probabilidades por clase)

## MÃ©trica y pÃ©rdida adecuadas
**PÃ©rdida**: `categorical_crossentropy` (etiquetas one-hot).  
**MÃ©trica principal**: `accuracy` (% aciertos).  
**Matriz de confusiÃ³n**: muestra quÃ© clases se confunden (ej. *cat â†” dog*), Ãºtil para detectar sesgos o clases difÃ­ciles.



## NormalizaciÃ³n y preparaciÃ³n de datos
Dividimos por 255.0 para llevar pÃ­xeles a [0,1] â†’ gradientes estables y LR mÃ¡s altas.  
**Estandarizar por canal** (media 0, desv 1) acelera convergencia en redes profundas o con SGD+momentum.  
Ambas mejoran la **estabilidad numÃ©rica** y permiten usar **tasas de aprendizaje mÃ¡s grandes** sin divergencia.

## Baseline denso vs CNN
MLP: 3072â†’256â†’10 â†’ â‰ˆ800 k parÃ¡metros, **sin sesgo espacial**, **sobreajusta** rÃ¡pido ante ruido de fondo.  
CNN: 55 k parÃ¡metros, **sesgo inductivo local** (vecinos â†’ patrones), **generaliza** mejor con menos datos y parÃ¡metros.  
La CNN **no aplan** la imagen â†’ conserva topologÃ­a y es **mÃ¡s robusta** a pequeÃ±as deformaciones.

## ParÃ¡metros y capacidad
Conv2D:  
`parÃ¡metros = (kernel_h Ã— kernel_w Ã— canales_entrada + 1) Ã— filtros_salida`  
Aumentar **kernel**, **filtros** o **profundidad** â†’ mÃ¡s capacidad, mÃ¡s tiempo y riesgo de sobreajuste.  
Profundidad crece capacidad **exponencialmente**; conviene equilibrar con regularizaciÃ³n.

## RegularizaciÃ³n prÃ¡ctica
1. **Dropout**: apaga neuronas (0.2-0.5) â†’ evita co-adaptaciÃ³n.  
2. **L2 weight decay**: penaliza pesos grandes (1e-4) â†’ pesos mÃ¡s pequeÃ±os.  
3. **Data Augmentation**: crea variedad artificial â†’ robustez.  
4. **Early Stopping**: para cuando val_loss no mejora â†’ ahorra tiempo y evita sobreajuste.  
**Combina** las 3 primeras; EarlyStopping siempre obligado.

## Data Augmentation con cabeza
Plan razonable CIFAR-10:  
- Flip horizontal (siempre).  
- RotaciÃ³n Â±10Â°.  
- TraslaciÃ³n 10 %.  
- Zoom 10 %.  
- Brillo Â±20 %.  
**LÃ­mites**: CIFAR-10 ya es natural â†’ evita distorsiones extremas, rotaciones &gt;20Â° o cambios de color fuertes.

## OptimizaciÃ³n y LR scheduling
**Adam**: adaptativo, rÃ¡pido, pero puede quedarse en mÃ­nimos locales.  
**SGD+momentum**: mÃ¡s lento, a veces **mejor generalizaciÃ³n**.  
**ReduceLROnPlateau**: baja LR cuando val_loss se estanca 3 Ã©pocas.  
**CosineDecay**: baja LR suavemente de 0.05 â†’ 0 en 30 Ã©pocas.  
**SeÃ±al**: val_loss sin mejora â†’ bajar LR.

## Curvas de aprendizaje
- **Subajuste**: train/val altas y paralelas â†’ aumenta capacidad.  
- **Ajuste saludable**: brecha pequeÃ±a y descendente.  
- **Sobreajuste**: train baja, val sube â†’ mÃ¡s regularizaciÃ³n.

## Matriz de confusiÃ³n y clase difÃ­cil
Pares tÃ­picos: *cat â†” dog*, *automobile â†” truck*, *deer â†” horse*.  
Mejoras: mÃ¡s datos de esas clases (augment dirigido), **label smoothing** o **focal loss**.

## Batch size y estabilidad
- **32**: ruido Ãºtil, generaliza mejor, Ã©poca lenta.  
- **128**: estable, Ã©poca rÃ¡pida, pero puede necesitar mÃ¡s Ã©pocas.  
**Valor inicial en Colab**: 64 (equilibrio tiempo/ruido).

## Buenas prÃ¡cticas de entrega
1. CÃ³digo limpio y comentado.  
2. Semillas fijadas (42).  
3. Logs completos (history.csv, metrics.json).  
4. Curvas y matriz de confusiÃ³n.  
5. Tabla comparativa MLP vs CNN.  
6. README con instrucciones de reproducciÃ³n.  
7. `requirements.txt` congelado.  
8. Tag de release (`v1.0-P3-CIFAR10_Apellido`).  
9. Informe PDF (2 pÃ¡gs).  
10. 5 hallazgos breves (ej. â€œaugment +2.3 % test accâ€).



## ğŸƒâ€â™‚ï¸ Uso rÃ¡pido
1. Clona y crea entorno:
```bash
git clone https://github.com/tu-usuario/IA_P3_CIFAR10_Apellido.git
cd IA_P3_CIFAR10_Apellido
python -m venv venv && source venv/bin/activate
pip install -r env/requirements.txt
```
2. Abre el notebook en Colab/Jupyter y ejecuta **Run all**.

## ğŸ“Š Resultados clave (resumen)
| Modelo                     | test acc | Ã©pocas | parÃ¡metros | notas |
|----------------------------|----------|--------|------------|-------|
| MLP (baseline)             | 0.XX     | 10     | 800 k      | overfit fuerte |
| CNN-2B                     | 0.XX     | 15     | 55 k       | â€” |
| CNN-2B + L2 + EarlyStop    | 0.XX     | XX     | 55 k       | brecha â†“ |
| CNN-3B + augment + sched   | **0.XX** | XX     | 200 k      | **mejor** |
| SGD + CosineDecay          | 0.XX     | XX     | 200 k      | similar, estable |

> Mejora final sobre MLP: **+XX %** con **4Ã— menos parÃ¡metros**.

## ğŸ” AblaciÃ³n (contribuciÃ³n de cada tÃ©cnica)
| Variante        | test acc | Î” vs todo |
|-----------------|----------|-----------|
| A todo          | 0.XX     | â€”         |
| B sin augment   | 0.XX     | -0.XX     |
| C sin L2        | 0.XX     | -0.XX     |
| D sin dropout   | 0.XX     | -0.XX     |

**ConclusiÃ³n**: *Data augmentation* es la tÃ©cnica **mÃ¡s influyente**.

## ğŸ§ª Reproducibilidad
| elemento        | valor                        |
|-----------------|------------------------------|
| seed            | 42                           |
| TensorFlow      | 2.15.0 (GPU habilitado)      |
| Python          | 3.10.12                      |
| commit          | `abc1234`                    |
| tag             | v1.0-P3-CIFAR10_Apellido     |
| hash datos      | `b5a2c1d8e7f9a1b2` (SHA-256) |

## âœï¸ PrÃ³ximos pasos
- Transfer learning con ResNet-20 â†’ objetivo 92 %.  
- Label smoothing / MixUp para reducir confusiÃ³n *cat â†” dog*.  
- Auto-augment para ganar generalizaciÃ³n extra.

## ğŸ“„ Licencia
Este trabajo acadÃ©mico se distribuye bolely under **CC BY-NC-SA 4.0**.
```

CÃ³mo usarlo:

1. En GitHub â†’ Add file â†’ Create new file â†’ pega el texto â†’ nombre `README.md` â†’ Commit.  
2. Cambia los `0.XX` por los valores que ya tienes en los `metrics_*.json`.  
3. AÃ±ade el tag y ya tienes un **repo profesional** listo para entregar.
